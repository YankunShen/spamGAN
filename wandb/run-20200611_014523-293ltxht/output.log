final_runner.py:116: DeprecationWarning: Importing from `texar` is deprecated. Please import from `texar.tf` instead, e.g. `import texar.tf as tx`
  vocab = texar.data.make_vocab([train_revs, test_revs, data_paths['unsup_train_data_reviews']], 10000)
Constructing graph...
Building model components...
Creating Generator MLE training subgraph...
Creating token sequence sampling subgraph...
Creating discriminator training subgraph...
Creating classifier training subgraph...
Creating policy gradient subgraph...
2020-06-10 18:45:42.449036: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-06-10 18:45:42.479987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-10 18:45:42.480817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71
pciBusID: 0000:42:00.0
2020-06-10 18:45:42.481106: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-06-10 18:45:42.482500: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-06-10 18:45:42.483934: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-06-10 18:45:42.484236: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-06-10 18:45:42.485901: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-06-10 18:45:42.487120: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-06-10 18:45:42.491159: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-06-10 18:45:42.491362: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-10 18:45:42.492262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-10 18:45:42.493028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-06-10 18:45:42.493525: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-10 18:45:42.596796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-10 18:45:42.597586: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x8fe0e10 executing computations on platform CUDA. Devices:
2020-06-10 18:45:42.597611: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080, Compute Capability 7.5
2020-06-10 18:45:42.600615: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3493065000 Hz
2020-06-10 18:45:42.603243: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x90dbf40 executing computations on platform Host. Devices:
2020-06-10 18:45:42.603306: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-06-10 18:45:42.603637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-10 18:45:42.604348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71
pciBusID: 0000:42:00.0
2020-06-10 18:45:42.604418: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-06-10 18:45:42.604447: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-06-10 18:45:42.604467: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-06-10 18:45:42.604484: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-06-10 18:45:42.604500: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-06-10 18:45:42.604516: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-06-10 18:45:42.604533: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-06-10 18:45:42.604597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-10 18:45:42.605267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-10 18:45:42.605817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-06-10 18:45:42.605855: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-06-10 18:45:42.607034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-10 18:45:42.607055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2020-06-10 18:45:42.607069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2020-06-10 18:45:42.607172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-10 18:45:42.607779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-10 18:45:42.608364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7452 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080, pci bus id: 0000:42:00.0, compute capability: 7.5)
2020-06-10 18:45:43.773147: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
Beginning data flow...
Starting generator pretraining...
Min Gen MLE val loss: 100000000.0

Total GPU runtime after generator pretrain: 0
Starting discriminator pretraining...

 Discriminator critic pretraining...

Total GPU runtime after discriminator pretrain: 0
Starting classifier pretraining...

Clas Pretrain Epoch 0
2020-06-10 18:45:50.134459: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
['/home/yankun/spamGAN_output/tr10_usp0_0_nogan/trevs.txt', '/home/yankun/spamGAN_output/tr10_usp0_0_nogan/unsup_trevs.txt']
Train Pcent 0.1 Unsup Pcent -1 Run 0
 128/5792 [..............................] - ETA: 2:05 - loss: 0.6960 - batch_time: 2.8500 - acc: 0.4609 - GPU_runtime: 2.8500 256/5792 [>.............................] - ETA: 1:18 - loss: 0.6956 - batch_time: 1.8100 - acc: 0.4648 - GPU_runtime: 3.2350 384/5792 [>.............................] - ETA: 1:01 - loss: 0.6944 - batch_time: 1.4567 - acc: 0.4687 - GPU_runtime: 3.6133 512/5792 [=>............................] - ETA: 53s - loss: 0.6946 - batch_time: 1.2925 - acc: 0.4668 - GPU_runtime: 4.0025  640/5792 [==>...........................] - ETA: 47s - loss: 0.6943 - batch_time: 1.1760 - acc: 0.4687 - GPU_runtime: 4.3780 768/5792 [==>...........................] - ETA: 43s - loss: 0.6945 - batch_time: 1.1034 - acc: 0.4753 - GPU_runtime: 4.7516 896/5792 [===>..........................] - ETA: 40s - loss: 0.6941 - batch_time: 1.0586 - acc: 0.4810 - GPU_runtime: 5.13141024/5792 [====>.........................] - ETA: 38s - loss: 0.6940 - batch_time: 1.0238 - acc: 0.4766 - GPU_runtime: 5.51371152/5792 [====>.........................] - ETA: 36s - loss: 0.6938 - batch_time: 0.9989 - acc: 0.4878 - GPU_runtime: 5.90001280/5792 [=====>........................] - ETA: 34s - loss: 0.6945 - batch_time: 0.9820 - acc: 0.4836 - GPU_runtime: 6.29201408/5792 [======>.......................] - ETA: 32s - loss: 0.6942 - batch_time: 0.9627 - acc: 0.4908 - GPU_runtime: 6.68271536/5792 [======>.......................] - ETA: 31s - loss: 0.6944 - batch_time: 0.9500 - acc: 0.4870 - GPU_runtime: 7.07581664/5792 [=======>......................] - ETA: 30s - loss: 0.6942 - batch_time: 0.9362 - acc: 0.4922 - GPU_runtime: 7.46771792/5792 [========>.....................] - ETA: 28s - loss: 0.6942 - batch_time: 0.9236 - acc: 0.4872 - GPU_runtime: 7.85781920/5792 [========>.....................] - ETA: 27s - loss: 0.6939 - batch_time: 0.9107 - acc: 0.4922 - GPU_runtime: 8.24462048/5792 [=========>....................] - ETA: 26s - loss: 0.6937 - batch_time: 0.9019 - acc: 0.4937 - GPU_runtime: 8.63122176/5792 [==========>...................] - ETA: 25s - loss: 0.6936 - batch_time: 0.8953 - acc: 0.4968 - GPU_runtime: 9.01882304/5792 [==========>...................] - ETA: 24s - loss: 0.6935 - batch_time: 0.8889 - acc: 0.4983 - GPU_runtime: 9.40662432/5792 [===========>..................] - ETA: 23s - loss: 0.6936 - batch_time: 0.8847 - acc: 0.4955 - GPU_runtime: 9.79632560/5792 [============>.................] - ETA: 22s - loss: 0.6933 - batch_time: 0.8805 - acc: 0.4973 - GPU_runtime: 10.18702688/5792 [============>.................] - ETA: 21s - loss: 0.6928 - batch_time: 0.8757 - acc: 0.5041 - GPU_runtime: 10.57762816/5792 [=============>................] - ETA: 20s - loss: 0.6928 - batch_time: 0.8696 - acc: 0.5053 - GPU_runtime: 10.96632944/5792 [==============>...............] - ETA: 19s - loss: 0.6927 - batch_time: 0.8639 - acc: 0.5058 - GPU_runtime: 11.35343072/5792 [==============>...............] - ETA: 18s - loss: 0.6928 - batch_time: 0.8608 - acc: 0.5036 - GPU_runtime: 11.74123200/5792 [===============>..............] - ETA: 17s - loss: 0.6927 - batch_time: 0.8568 - acc: 0.5044 - GPU_runtime: 12.12843328/5792 [================>.............] - ETA: 16s - loss: 0.6926 - batch_time: 0.8539 - acc: 0.5045 - GPU_runtime: 12.51573456/5792 [================>.............] - ETA: 15s - loss: 0.6927 - batch_time: 0.8504 - acc: 0.5043 - GPU_runtime: 12.90263584/5792 [=================>............] - ETA: 14s - loss: 0.6927 - batch_time: 0.8489 - acc: 0.5053 - GPU_runtime: 13.29073712/5792 [==================>...........] - ETA: 13s - loss: 0.6927 - batch_time: 0.8455 - acc: 0.5048 - GPU_runtime: 13.67793840/5792 [==================>...........] - ETA: 12s - loss: 0.6926 - batch_time: 0.8433 - acc: 0.5060 - GPU_runtime: 14.06533968/5792 [===================>..........] - ETA: 12s - loss: 0.6926 - batch_time: 0.8416 - acc: 0.5068 - GPU_runtime: 14.45324096/5792 [====================>.........] - ETA: 11s - loss: 0.6927 - batch_time: 0.8394 - acc: 0.5061 - GPU_runtime: 14.84094224/5792 [====================>.........] - ETA: 10s - loss: 0.6928 - batch_time: 0.8373 - acc: 0.5054 - GPU_runtime: 15.22854352/5792 [=====================>........] - ETA: 9s - loss: 0.6928 - batch_time: 0.8368 - acc: 0.5057 - GPU_runtime: 15.6173 4480/5792 [======================>.......] - ETA: 8s - loss: 0.6927 - batch_time: 0.8354 - acc: 0.5065 - GPU_runtime: 16.00654608/5792 [======================>.......] - ETA: 7s - loss: 0.6927 - batch_time: 0.8328 - acc: 0.5059 - GPU_runtime: 16.39474736/5792 [=======================>......] - ETA: 6s - loss: 0.6927 - batch_time: 0.8324 - acc: 0.5080 - GPU_runtime: 16.78404864/5792 [========================>.....] - ETA: 6s - loss: 0.6927 - batch_time: 0.8324 - acc: 0.5082 - GPU_runtime: 17.17474992/5792 [========================>.....] - ETA: 5s - loss: 0.6927 - batch_time: 0.8303 - acc: 0.5088 - GPU_runtime: 17.56465120/5792 [=========================>....] - ETA: 4s - loss: 0.6927 - batch_time: 0.8290 - acc: 0.5084 - GPU_runtime: 17.95455248/5792 [==========================>...] - ETA: 3s - loss: 0.6927 - batch_time: 0.8281 - acc: 0.5078 - GPU_runtime: 18.34465376/5792 [==========================>...] - ETA: 2s - loss: 0.6927 - batch_time: 0.8262 - acc: 0.5076 - GPU_runtime: 18.73405504/5792 [===========================>..] - ETA: 1s - loss: 0.6926 - batch_time: 0.8254 - acc: 0.5082 - GPU_runtime: 19.12375632/5792 [============================>.] - ETA: 1s - loss: 0.6926 - batch_time: 0.8239 - acc: 0.5092 - GPU_runtime: 19.51295760/5792 [============================>.] - ETA: 0s - loss: 0.6928 - batch_time: 0.8222 - acc: 0.5073 - GPU_runtime: 19.90155792/5792 [==============================] - 38s 7ms/step - loss: 0.6928 - batch_time: 0.8217 - acc: 0.5081 - GPU_runtime: 20.0000
Traceback (most recent call last):
  File "final_runner.py", line 157, in <module>
    dict_res = spamGAN_train.main(base_config)
  File "/home/yankun/spamGAN/spamGAN_train.py", line 1592, in main
    clas_rtns = clas_run_epoch(sess, 'pretrain', sum_writer, clas_rtns['step'])
  File "/home/yankun/spamGAN/spamGAN_train.py", line 1468, in clas_run_epoch
    output["real_prec"] = real_prec
UnboundLocalError: local variable 'real_prec' referenced before assignment
